{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7082c8b7",
      "metadata": {},
      "source": [
        "# Deploy Trained Smolvla Policy\n",
        "\n",
        "<img src=\"./media/rollout3.gif\" width=\"480\" height=\"360\">\n",
        "\n",
        "Deploy trained policy in simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ab95e0af",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Requirement already satisfied: transformers==4.50.3 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /home/dragon/.local/lib/python3.10/site-packages (from transformers==4.50.3) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from transformers==4.50.3) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from transformers==4.50.3) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dragon/.local/lib/python3.10/site-packages (from transformers==4.50.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from transformers==4.50.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from transformers==4.50.3) (2025.9.1)\n",
            "Requirement already satisfied: requests in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from transformers==4.50.3) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from transformers==4.50.3) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from transformers==4.50.3) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from transformers==4.50.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/dragon/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dragon/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.3) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from requests->transformers==4.50.3) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from requests->transformers==4.50.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from requests->transformers==4.50.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from requests->transformers==4.50.3) (2025.8.3)\n",
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Requirement already satisfied: num2words in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (0.5.14)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from num2words) (0.6.2)\n",
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Requirement already satisfied: accelerate in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from accelerate) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dragon/.local/lib/python3.10/site-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /home/dragon/.local/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from accelerate) (2.7.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from accelerate) (0.35.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /home/dragon/.local/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/dragon/.local/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dragon/.local/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.9)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/dragon/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from triton==3.3.1->torch>=2.0.0->accelerate) (80.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dragon/.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.50.3\n",
        "!pip install num2words\n",
        "!pip install accelerate\n",
        "!pip install safetensors>=0.4.3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20673462",
      "metadata": {},
      "source": [
        "## Step 3. Deploy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "07386e5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/dragon/anaconda3/envs/mujoco_vla/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Dataset imports - moved from lerobot.common.datasets\n",
        "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
        "from lerobot.datasets.utils import write_json, serialize_dict, dataset_to_policy_features\n",
        "from lerobot.datasets.factory import resolve_delta_timestamps\n",
        "\n",
        "# SmolVLA policy imports - moved from lerobot.common.policies\n",
        "from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
        "from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
        "\n",
        "# Config types - moved from lerobot.configs\n",
        "from lerobot.configs.types import FeatureType\n",
        "\n",
        "# Standard imports remain the same\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0b1f651f",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "381de80f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Device 'None' is not available. Switching to 'cuda'.\n"
          ]
        }
      ],
      "source": [
        "dataset_name = 'remove_red_block_from_plate_so100_smolvla_mujoco'\n",
        "try:\n",
        "    dataset_metadata = LeRobotDatasetMetadata(dataset_name, root='./demo_data_language')\n",
        "except Exception:\n",
        "    dataset_metadata = LeRobotDatasetMetadata(dataset_name, root='./demo_data_language')\n",
        "features = dataset_to_policy_features(dataset_metadata.features)\n",
        "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
        "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
        "# Policies are initialized with a configuration class, in this case `DiffusionConfig`. For this example,\n",
        "# we'll just use the defaults and so no arguments other than input/output features need to be passed.\n",
        "# Temporal ensemble to make smoother trajectory predictions\n",
        "cfg = SmolVLAConfig(input_features=input_features, output_features=output_features, chunk_size= 5, n_action_steps=5)\n",
        "delta_timestamps = resolve_delta_timestamps(cfg, dataset_metadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5e38030a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reducing the number of VLM layers to 16 ...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SmolVLAPolicy(\n",
              "  (normalize_inputs): Normalize(\n",
              "    (buffer_observation_state): ParameterDict(\n",
              "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
              "        (std): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
              "    )\n",
              "    (buffer_observation_block_pose): ParameterDict(\n",
              "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
              "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
              "    )\n",
              "  )\n",
              "  (normalize_targets): Normalize(\n",
              "    (buffer_action): ParameterDict(\n",
              "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
              "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
              "    )\n",
              "  )\n",
              "  (unnormalize_outputs): Unnormalize(\n",
              "    (buffer_action): ParameterDict(\n",
              "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
              "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
              "    )\n",
              "  )\n",
              "  (model): VLAFlowMatching(\n",
              "    (vlm_with_expert): SmolVLMWithExpertModel(\n",
              "      (vlm): SmolVLMForConditionalGeneration(\n",
              "        (model): SmolVLMModel(\n",
              "          (vision_model): SmolVLMVisionTransformer(\n",
              "            (embeddings): SmolVLMVisionEmbeddings(\n",
              "              (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), padding=valid)\n",
              "              (position_embedding): Embedding(1024, 768)\n",
              "            )\n",
              "            (encoder): SmolVLMEncoder(\n",
              "              (layers): ModuleList(\n",
              "                (0-11): 12 x SmolVLMEncoderLayer(\n",
              "                  (self_attn): SmolVLMVisionAttention(\n",
              "                    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  )\n",
              "                  (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                  (mlp): SmolVLMVisionMLP(\n",
              "                    (activation_fn): PytorchGELUTanh()\n",
              "                    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                  )\n",
              "                  (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (post_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "          (connector): SmolVLMConnector(\n",
              "            (modality_projection): SmolVLMSimpleMLP(\n",
              "              (proj): Linear(in_features=12288, out_features=960, bias=False)\n",
              "            )\n",
              "          )\n",
              "          (text_model): LlamaModel(\n",
              "            (embed_tokens): Embedding(49280, 960, padding_idx=2)\n",
              "            (layers): ModuleList(\n",
              "              (0-15): 16 x LlamaDecoderLayer(\n",
              "                (self_attn): LlamaAttention(\n",
              "                  (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
              "                  (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
              "                  (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
              "                  (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
              "                )\n",
              "                (mlp): LlamaMLP(\n",
              "                  (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
              "                  (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
              "                  (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
              "                  (act_fn): SiLU()\n",
              "                )\n",
              "                (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
              "                (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
              "              )\n",
              "            )\n",
              "            (norm): LlamaRMSNorm((960,), eps=1e-05)\n",
              "            (rotary_emb): LlamaRotaryEmbedding()\n",
              "          )\n",
              "        )\n",
              "        (lm_head): Linear(in_features=960, out_features=49280, bias=False)\n",
              "      )\n",
              "      (lm_expert): LlamaModel(\n",
              "        (embed_tokens): None\n",
              "        (layers): ModuleList(\n",
              "          (0): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (1): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (2): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (3): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (4): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (5): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (6): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (7): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (8): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (9): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (10): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (11): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (12): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (13): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (14): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "          (15): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
              "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
              "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
              "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((720,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "    )\n",
              "    (state_proj): Linear(in_features=32, out_features=960, bias=True)\n",
              "    (action_in_proj): Linear(in_features=32, out_features=720, bias=True)\n",
              "    (action_out_proj): Linear(in_features=720, out_features=32, bias=True)\n",
              "    (action_time_mlp_in): Linear(in_features=1440, out_features=720, bias=True)\n",
              "    (action_time_mlp_out): Linear(in_features=720, out_features=720, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# policy_path = './ckpt/smolvla_omy/checkpoints/last/pretrained_model'\n",
        "# policy = SmolVLAPolicy.from_pretrained(\n",
        "#     policy_path,\n",
        "#     dataset_stats=dataset_metadata.stats,\n",
        "# )\n",
        "policy = SmolVLAPolicy.from_pretrained(\"DragonHu/lerobot_remove_block_uniform_ramdom_smolvla_base\", config=cfg, dataset_stats=dataset_metadata.stats)\n",
        "\n",
        "\n",
        "\n",
        "policy.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "85ebd9c8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "-----------------------------------------------------------------------------\n",
            "name:[Tabletop] dt:[0.002] HZ:[500]\n",
            " n_qpos:[27] n_qvel:[24] n_qacc:[24] n_ctrl:[6]\n",
            " integrator:[RK4]\n",
            "\n",
            "n_body:[18]\n",
            " [0/18] [world] mass:[0.00]kg\n",
            " [1/18] [front_object_table] mass:[1.00]kg\n",
            " [2/18] [camera] mass:[0.00]kg\n",
            " [3/18] [camera2] mass:[0.00]kg\n",
            " [4/18] [camera3] mass:[0.00]kg\n",
            " [5/18] [Base] mass:[0.56]kg\n",
            " [6/18] [Rotation_Pitch] mass:[0.12]kg\n",
            " [7/18] [Upper_Arm] mass:[0.16]kg\n",
            " [8/18] [Lower_Arm] mass:[0.15]kg\n",
            " [9/18] [Wrist_Pitch_Roll] mass:[0.07]kg\n",
            " [10/18] [Fixed_Jaw] mass:[0.09]kg\n",
            " [11/18] [camera_center] mass:[0.00]kg\n",
            " [12/18] [Moving_Jaw] mass:[0.02]kg\n",
            " [13/18] [body_obj_plate_11] mass:[0.00]kg\n",
            " [14/18] [object_plate_11] mass:[0.10]kg\n",
            " [15/18] [body_obj_mug_6] mass:[0.00]kg\n",
            " [16/18] [object_mug_6] mass:[0.08]kg\n",
            " [17/18] [body_obj_block_red] mass:[0.30]kg\n",
            "body_total_mass:[2.66]kg\n",
            "\n",
            "n_geom:[101]\n",
            "geom_names:['floor', 'front_object_table', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'fixed_jaw_pad_1', 'fixed_jaw_pad_2', 'fixed_jaw_pad_3', 'fixed_jaw_pad_4', None, None, None, None, None, 'moving_jaw_pad_1', 'moving_jaw_pad_2', 'moving_jaw_pad_3', 'moving_jaw_pad_4', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'body_obj_block_red']\n",
            "\n",
            "n_mesh:[84]\n",
            "mesh_names:['Base', 'Base_Motor', 'Rotation_Pitch', 'Rotation_Pitch_Motor', 'Upper_Arm', 'Upper_Arm_Motor', 'Lower_Arm', 'Lower_Arm_Motor', 'Wrist_Pitch_Roll', 'Wrist_Pitch_Roll_Motor', 'Fixed_Jaw', 'Fixed_Jaw_Motor', 'Fixed_Jaw_Collision_1', 'Fixed_Jaw_Collision_2', 'Moving_Jaw', 'Moving_Jaw_Collision_1', 'Moving_Jaw_Collision_2', 'Moving_Jaw_Collision_3', 'plate_11_normalized_0_vis', 'plate_11_normalized_collision_22._coll', 'plate_11_normalized_collision_23._coll', 'plate_11_normalized_collision_21._coll', 'plate_11_normalized_collision_20._coll', 'plate_11_normalized_collision_24._coll', 'plate_11_normalized_collision_30._coll', 'plate_11_normalized_collision_18._coll', 'plate_11_normalized_collision_19._coll', 'plate_11_normalized_collision_31._coll', 'plate_11_normalized_collision_25._coll', 'plate_11_normalized_collision_27._coll', 'plate_11_normalized_collision_26._coll', 'plate_11_normalized_collision_9._coll', 'plate_11_normalized_collision_8._coll', 'plate_11_normalized_collision_6._coll', 'plate_11_normalized_collision_7._coll', 'plate_11_normalized_collision_5._coll', 'plate_11_normalized_collision_4._coll', 'plate_11_normalized_collision_0._coll', 'plate_11_normalized_collision_1._coll', 'plate_11_normalized_collision_3._coll', 'plate_11_normalized_collision_2._coll', 'plate_11_normalized_collision_17._coll', 'plate_11_normalized_collision_16._coll', 'plate_11_normalized_collision_28._coll', 'plate_11_normalized_collision_14._coll', 'plate_11_normalized_collision_15._coll', 'plate_11_normalized_collision_29._coll', 'plate_11_normalized_collision_11._coll', 'plate_11_normalized_collision_10._coll', 'plate_11_normalized_collision_12._coll', 'plate_11_normalized_collision_13._coll', 'mug_6_normalized_0_vis', 'mug_6_normalized_collision_22._coll', 'mug_6_normalized_collision_23._coll', 'mug_6_normalized_collision_21._coll', 'mug_6_normalized_collision_20._coll', 'mug_6_normalized_collision_24._coll', 'mug_6_normalized_collision_30._coll', 'mug_6_normalized_collision_18._coll', 'mug_6_normalized_collision_19._coll', 'mug_6_normalized_collision_31._coll', 'mug_6_normalized_collision_25._coll', 'mug_6_normalized_collision_27._coll', 'mug_6_normalized_collision_26._coll', 'mug_6_normalized_collision_9._coll', 'mug_6_normalized_collision_8._coll', 'mug_6_normalized_collision_6._coll', 'mug_6_normalized_collision_7._coll', 'mug_6_normalized_collision_5._coll', 'mug_6_normalized_collision_4._coll', 'mug_6_normalized_collision_0._coll', 'mug_6_normalized_collision_1._coll', 'mug_6_normalized_collision_3._coll', 'mug_6_normalized_collision_2._coll', 'mug_6_normalized_collision_17._coll', 'mug_6_normalized_collision_16._coll', 'mug_6_normalized_collision_28._coll', 'mug_6_normalized_collision_14._coll', 'mug_6_normalized_collision_15._coll', 'mug_6_normalized_collision_29._coll', 'mug_6_normalized_collision_11._coll', 'mug_6_normalized_collision_10._coll', 'mug_6_normalized_collision_12._coll', 'mug_6_normalized_collision_13._coll']\n",
            "\n",
            "n_joint:[9]\n",
            " [0/9] [Rotation] axis:[0. 1. 0.]\n",
            " [1/9] [Pitch] axis:[1. 0. 0.]\n",
            " [2/9] [Elbow] axis:[1. 0. 0.]\n",
            " [3/9] [Wrist_Pitch] axis:[1. 0. 0.]\n",
            " [4/9] [Wrist_Roll] axis:[0. 1. 0.]\n",
            " [5/9] [Jaw] axis:[0. 0. 1.]\n",
            " [6/9] [None] axis:[0. 0. 1.]\n",
            " [7/9] [None] axis:[0. 0. 1.]\n",
            " [8/9] [body_obj_block_red] axis:[0. 0. 1.]\n",
            "\n",
            "n_dof:[24] (=number of rows of Jacobian)\n",
            " [0/24] [None] attached joint:[Rotation] body:[Rotation_Pitch]\n",
            " [1/24] [None] attached joint:[Pitch] body:[Upper_Arm]\n",
            " [2/24] [None] attached joint:[Elbow] body:[Lower_Arm]\n",
            " [3/24] [None] attached joint:[Wrist_Pitch] body:[Wrist_Pitch_Roll]\n",
            " [4/24] [None] attached joint:[Wrist_Roll] body:[Fixed_Jaw]\n",
            " [5/24] [None] attached joint:[Jaw] body:[Moving_Jaw]\n",
            " [6/24] [None] attached joint:[None] body:[body_obj_plate_11]\n",
            " [7/24] [None] attached joint:[None] body:[body_obj_plate_11]\n",
            " [8/24] [None] attached joint:[None] body:[body_obj_plate_11]\n",
            " [9/24] [None] attached joint:[None] body:[body_obj_plate_11]\n",
            " [10/24] [None] attached joint:[None] body:[body_obj_plate_11]\n",
            " [11/24] [None] attached joint:[None] body:[body_obj_plate_11]\n",
            " [12/24] [None] attached joint:[None] body:[body_obj_mug_6]\n",
            " [13/24] [None] attached joint:[None] body:[body_obj_mug_6]\n",
            " [14/24] [None] attached joint:[None] body:[body_obj_mug_6]\n",
            " [15/24] [None] attached joint:[None] body:[body_obj_mug_6]\n",
            " [16/24] [None] attached joint:[None] body:[body_obj_mug_6]\n",
            " [17/24] [None] attached joint:[None] body:[body_obj_mug_6]\n",
            " [18/24] [None] attached joint:[body_obj_block_red] body:[body_obj_block_red]\n",
            " [19/24] [None] attached joint:[body_obj_block_red] body:[body_obj_block_red]\n",
            " [20/24] [None] attached joint:[body_obj_block_red] body:[body_obj_block_red]\n",
            " [21/24] [None] attached joint:[body_obj_block_red] body:[body_obj_block_red]\n",
            " [22/24] [None] attached joint:[body_obj_block_red] body:[body_obj_block_red]\n",
            " [23/24] [None] attached joint:[body_obj_block_red] body:[body_obj_block_red]\n",
            "\n",
            "Free joint information. n_free_joint:[3]\n",
            " [0/3] [None] body_name_attached:[body_obj_plate_11]\n",
            " [1/3] [None] body_name_attached:[body_obj_mug_6]\n",
            " [2/3] [body_obj_block_red] body_name_attached:[body_obj_block_red]\n",
            "\n",
            "Revolute joint information. n_rev_joint:[6]\n",
            " [0/6] [Rotation] range:[-2.200]~[2.200]\n",
            " [1/6] [Pitch] range:[-3.142]~[0.200]\n",
            " [2/6] [Elbow] range:[0.000]~[3.142]\n",
            " [3/6] [Wrist_Pitch] range:[-2.000]~[1.800]\n",
            " [4/6] [Wrist_Roll] range:[-3.142]~[3.142]\n",
            " [5/6] [Jaw] range:[-0.200]~[1.800]\n",
            "\n",
            "Prismatic joint information. n_pri_joint:[0]\n",
            "\n",
            "Control information. n_ctrl:[6]\n",
            " [0/6] [Rotation] range:[-3.142]~[3.142] gear:[1.00] type:[JOINT]\n",
            " [1/6] [Pitch] range:[-3.142]~[3.142] gear:[1.00] type:[JOINT]\n",
            " [2/6] [Elbow] range:[-3.142]~[3.142] gear:[1.00] type:[JOINT]\n",
            " [3/6] [Wrist_Pitch] range:[-3.142]~[3.142] gear:[1.00] type:[JOINT]\n",
            " [4/6] [Wrist_Roll] range:[-3.142]~[3.142] gear:[1.00] type:[JOINT]\n",
            " [5/6] [Jaw] range:[-3.142]~[3.142] gear:[1.00] type:[JOINT]\n",
            "\n",
            "Camera information. n_cam:[4]\n",
            " [0/4] [agentview] fov:[60.0]\n",
            " [1/4] [topview] fov:[90.0]\n",
            " [2/4] [sideview] fov:[90.0]\n",
            " [3/4] [egocentric] fov:[65.0]\n",
            "\n",
            "n_sensor:[0]\n",
            "sensor_names:[]\n",
            "n_site:[6]\n",
            "site_names:['bottom_site_plate_11', 'top_site_plate_11', 'horizontal_radius_site_plate_11', 'bottom_site_mug_6', 'top_site_mug_6', 'horizontal_radius_site_mug_6']\n",
            "-----------------------------------------------------------------------------\n",
            "env:[Tabletop] reset\n",
            "env:[Tabletop] reset\n",
            "env:[Tabletop] initalize viewer\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n"
          ]
        }
      ],
      "source": [
        "from mujoco_env.y_env2_removeBlock_Test_random import EnvRemoveBlockTestRandom\n",
        "xml_path = './asset/scene_remove_block_so100.xml'\n",
        "PnPEnv = EnvRemoveBlockTestRandom(\n",
        "    xml_path,\n",
        "    action_type='joint_angle',\n",
        "    random_block_position=False,\n",
        "    plate_flat_radius=0.102,\n",
        "    sampling_method='uniform',\n",
        "    seed=25,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "db761f31",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "# Approach 1: Using torchvision.transforms\n",
        "def get_default_transform(image_size: int = 224):\n",
        "    \"\"\"\n",
        "    Returns a torchvision transform that:\n",
        "     Converts to a FloatTensor and scales pixel values [0,255] -> [0.0,1.0]\n",
        "    \"\"\"\n",
        "    return transforms.Compose([\n",
        "        transforms.ToTensor(),  # PIL [0255] -> FloatTensor [0.01.0], shape CHW\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fef1d83b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ":\n",
            "- : 20\n",
            "- : 90 \n",
            "- : 30.0 \n",
            "...\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "# \n",
        "\n",
        "# \n",
        "TEST_ROUNDS = 20  # 10\n",
        "\n",
        "# \n",
        "TIMEOUT_SECONDS = 90  # 2\n",
        "\n",
        "# \n",
        "PnPEnv.task_timeout = TIMEOUT_SECONDS\n",
        "\n",
        "print(f\":\")\n",
        "print(f\"- : {TEST_ROUNDS}\")\n",
        "print(f\"- : {TIMEOUT_SECONDS} \")\n",
        "print(f\"- : {TEST_ROUNDS * TIMEOUT_SECONDS / 60:.1f} \")\n",
        "print(\"...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0a7d54a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 20 \n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            " 20 SmolVLA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4879/4271580188.py:49: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  'observation.state': torch.tensor([state]).to(device),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ": 1/20, : 2.1s, : remove_red_block\n",
            ": 1/20, : 3.7s, : remove_red_block\n",
            ": 1/20, : 5.2s, : remove_red_block\n",
            ": 1/20, : 6.7s, : remove_red_block\n",
            ": 1/20, : 8.2s, : remove_red_block\n",
            ": 1/20, : 9.7s, : remove_red_block\n",
            ": 1/20, : 11.2s, : remove_red_block\n",
            ": 1/20, : 12.7s, : remove_red_block\n",
            ": 1/20, : 14.2s, : remove_red_block\n",
            "\n",
            "!\n",
            " 1 : 14.8\n",
            " 2 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 2/20, : 1.6s, : remove_red_block\n",
            ": 2/20, : 3.2s, : remove_red_block\n",
            ": 2/20, : 4.7s, : remove_red_block\n",
            ": 2/20, : 6.2s, : remove_red_block\n",
            ": 2/20, : 7.7s, : remove_red_block\n",
            ": 2/20, : 9.3s, : remove_red_block\n",
            ": 2/20, : 10.8s, : remove_red_block\n",
            ": 2/20, : 12.3s, : remove_red_block\n",
            ": 2/20, : 13.8s, : remove_red_block\n",
            ": 2/20, : 15.4s, : remove_red_block\n",
            "\n",
            "!\n",
            " 2 : 16.1\n",
            " 3 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 3/20, : 1.7s, : remove_red_block\n",
            ": 3/20, : 3.2s, : remove_red_block\n",
            ": 3/20, : 4.7s, : remove_red_block\n",
            ": 3/20, : 6.2s, : remove_red_block\n",
            ": 3/20, : 7.8s, : remove_red_block\n",
            ": 3/20, : 9.3s, : remove_red_block\n",
            ": 3/20, : 10.8s, : remove_red_block\n",
            ": 3/20, : 12.3s, : remove_red_block\n",
            "\n",
            "!\n",
            " 3 : 13.5\n",
            " 4 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 4/20, : 1.7s, : remove_red_block\n",
            ": 4/20, : 3.2s, : remove_red_block\n",
            ": 4/20, : 4.7s, : remove_red_block\n",
            ": 4/20, : 6.2s, : remove_red_block\n",
            ": 4/20, : 7.7s, : remove_red_block\n",
            ": 4/20, : 9.2s, : remove_red_block\n",
            ": 4/20, : 10.7s, : remove_red_block\n",
            ": 4/20, : 12.2s, : remove_red_block\n",
            "\n",
            "!\n",
            " 4 : 13.6\n",
            " 5 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 5/20, : 1.6s, : remove_red_block\n",
            ": 5/20, : 3.1s, : remove_red_block\n",
            ": 5/20, : 4.6s, : remove_red_block\n",
            ": 5/20, : 6.2s, : remove_red_block\n",
            ": 5/20, : 7.7s, : remove_red_block\n",
            ": 5/20, : 9.2s, : remove_red_block\n",
            ": 5/20, : 10.7s, : remove_red_block\n",
            ": 5/20, : 12.2s, : remove_red_block\n",
            "\n",
            "!\n",
            " 5 : 13.6\n",
            " 6 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 6/20, : 1.6s, : remove_red_block\n",
            ": 6/20, : 3.1s, : remove_red_block\n",
            ": 6/20, : 4.7s, : remove_red_block\n",
            ": 6/20, : 6.2s, : remove_red_block\n",
            ": 6/20, : 7.7s, : remove_red_block\n",
            ": 6/20, : 9.3s, : remove_red_block\n",
            ": 6/20, : 10.8s, : remove_red_block\n",
            ": 6/20, : 12.3s, : remove_red_block\n",
            "\n",
            "!\n",
            " 6 : 13.0\n",
            " 7 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 7/20, : 1.7s, : remove_red_block\n",
            ": 7/20, : 3.2s, : remove_red_block\n",
            ": 7/20, : 4.7s, : remove_red_block\n",
            ": 7/20, : 6.2s, : remove_red_block\n",
            ": 7/20, : 7.8s, : remove_red_block\n",
            ": 7/20, : 9.3s, : remove_red_block\n",
            ": 7/20, : 10.8s, : remove_red_block\n",
            ": 7/20, : 12.4s, : remove_red_block\n",
            "\n",
            "!\n",
            " 7 : 13.4\n",
            " 8 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 8/20, : 1.7s, : remove_red_block\n",
            ": 8/20, : 3.2s, : remove_red_block\n",
            ": 8/20, : 4.7s, : remove_red_block\n",
            ": 8/20, : 6.2s, : remove_red_block\n",
            ": 8/20, : 7.7s, : remove_red_block\n",
            ": 8/20, : 9.3s, : remove_red_block\n",
            ": 8/20, : 10.8s, : remove_red_block\n",
            ": 8/20, : 12.3s, : remove_red_block\n",
            "\n",
            "!\n",
            " 8 : 13.3\n",
            " 9 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 9/20, : 1.7s, : remove_red_block\n",
            ": 9/20, : 3.1s, : remove_red_block\n",
            ": 9/20, : 4.6s, : remove_red_block\n",
            ": 9/20, : 6.1s, : remove_red_block\n",
            ": 9/20, : 7.7s, : remove_red_block\n",
            ": 9/20, : 9.2s, : remove_red_block\n",
            ": 9/20, : 10.7s, : remove_red_block\n",
            ": 9/20, : 12.2s, : remove_red_block\n",
            ": 9/20, : 13.7s, : remove_red_block\n",
            "\n",
            "!\n",
            " 9 : 14.1\n",
            " 10 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 10/20, : 1.7s, : remove_red_block\n",
            ": 10/20, : 3.2s, : remove_red_block\n",
            ": 10/20, : 4.7s, : remove_red_block\n",
            ": 10/20, : 6.2s, : remove_red_block\n",
            ": 10/20, : 7.7s, : remove_red_block\n",
            ": 10/20, : 9.2s, : remove_red_block\n",
            ": 10/20, : 10.7s, : remove_red_block\n",
            ": 10/20, : 12.3s, : remove_red_block\n",
            "\n",
            "!\n",
            " 10 : 13.3\n",
            " 11 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 11/20, : 1.7s, : remove_red_block\n",
            ": 11/20, : 3.2s, : remove_red_block\n",
            ": 11/20, : 4.7s, : remove_red_block\n",
            ": 11/20, : 6.3s, : remove_red_block\n",
            ": 11/20, : 7.8s, : remove_red_block\n",
            ": 11/20, : 9.3s, : remove_red_block\n",
            ": 11/20, : 10.8s, : remove_red_block\n",
            ": 11/20, : 12.4s, : remove_red_block\n",
            ": 11/20, : 13.9s, : remove_red_block\n",
            "\n",
            "!\n",
            " 11 : 15.3\n",
            " 12 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 12/20, : 1.7s, : remove_red_block\n",
            ": 12/20, : 3.2s, : remove_red_block\n",
            ": 12/20, : 4.7s, : remove_red_block\n",
            ": 12/20, : 6.2s, : remove_red_block\n",
            ": 12/20, : 7.7s, : remove_red_block\n",
            ": 12/20, : 9.2s, : remove_red_block\n",
            ": 12/20, : 10.7s, : remove_red_block\n",
            ": 12/20, : 12.3s, : remove_red_block\n",
            ": 12/20, : 13.8s, : remove_red_block\n",
            "\n",
            "!\n",
            " 12 : 15.2\n",
            " 13 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 13/20, : 1.6s, : remove_red_block\n",
            ": 13/20, : 3.1s, : remove_red_block\n",
            ": 13/20, : 4.7s, : remove_red_block\n",
            ": 13/20, : 6.2s, : remove_red_block\n",
            ": 13/20, : 7.7s, : remove_red_block\n",
            ": 13/20, : 9.3s, : remove_red_block\n",
            ": 13/20, : 10.8s, : remove_red_block\n",
            ": 13/20, : 12.3s, : remove_red_block\n",
            ": 13/20, : 13.8s, : remove_red_block\n",
            "\n",
            "!\n",
            " 13 : 14.9\n",
            " 14 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 14/20, : 1.7s, : remove_red_block\n",
            ": 14/20, : 3.2s, : remove_red_block\n",
            ": 14/20, : 4.7s, : remove_red_block\n",
            ": 14/20, : 6.2s, : remove_red_block\n",
            ": 14/20, : 7.8s, : remove_red_block\n",
            ": 14/20, : 9.3s, : remove_red_block\n",
            ": 14/20, : 10.8s, : remove_red_block\n",
            ": 14/20, : 12.3s, : remove_red_block\n",
            ": 14/20, : 13.9s, : remove_red_block\n",
            "\n",
            "!\n",
            " 14 : 14.3\n",
            " 15 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 15/20, : 1.7s, : remove_red_block\n",
            ": 15/20, : 3.2s, : remove_red_block\n",
            ": 15/20, : 4.7s, : remove_red_block\n",
            ": 15/20, : 6.2s, : remove_red_block\n",
            ": 15/20, : 7.8s, : remove_red_block\n",
            ": 15/20, : 9.2s, : remove_red_block\n",
            ": 15/20, : 10.8s, : remove_red_block\n",
            ": 15/20, : 12.3s, : remove_red_block\n",
            ": 15/20, : 13.8s, : remove_red_block\n",
            ": 15/20, : 15.3s, : remove_red_block\n",
            ": 15/20, : 16.8s, : remove_red_block\n",
            ": 15/20, : 18.4s, : remove_red_block\n",
            ": 15/20, : 19.9s, : remove_red_block\n",
            ": 15/20, : 21.4s, : remove_red_block\n",
            ": 15/20, : 22.9s, : remove_red_block\n",
            ": 15/20, : 24.4s, : remove_red_block\n",
            ": 15/20, : 26.0s, : remove_red_block\n",
            ": 15/20, : 27.5s, : remove_red_block\n",
            ": 15/20, : 29.0s, : remove_red_block\n",
            ": 15/20, : 30.6s, : remove_red_block\n",
            ": 15/20, : 32.1s, : remove_red_block\n",
            ": 15/20, : 33.6s, : remove_red_block\n",
            ": 15/20, : 35.2s, : remove_red_block\n",
            ": 15/20, : 36.7s, : remove_red_block\n",
            ": 15/20, : 38.2s, : remove_red_block\n",
            ": 15/20, : 39.8s, : remove_red_block\n",
            ": 15/20, : 41.4s, : remove_red_block\n",
            ": 15/20, : 43.0s, : remove_red_block\n",
            ": 15/20, : 44.6s, : remove_red_block\n",
            ": 15/20, : 46.2s, : remove_red_block\n",
            ": 15/20, : 47.7s, : remove_red_block\n",
            ": 15/20, : 49.2s, : remove_red_block\n",
            ": 15/20, : 50.7s, : remove_red_block\n",
            ": 15/20, : 52.3s, : remove_red_block\n",
            ": 15/20, : 53.8s, : remove_red_block\n",
            ": 15/20, : 55.3s, : remove_red_block\n",
            ": 15/20, : 56.9s, : remove_red_block\n",
            ": 15/20, : 58.4s, : remove_red_block\n",
            ": 15/20, : 60.0s, : remove_red_block\n",
            ": 15/20, : 61.5s, : remove_red_block\n",
            ": 15/20, : 63.0s, : remove_red_block\n",
            ": 15/20, : 64.6s, : remove_red_block\n",
            ": 15/20, : 66.1s, : remove_red_block\n",
            ": 15/20, : 67.7s, : remove_red_block\n",
            "\n",
            "!\n",
            " 15 : 68.0\n",
            " 16 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 16/20, : 1.7s, : remove_red_block\n",
            ": 16/20, : 3.2s, : remove_red_block\n",
            ": 16/20, : 4.7s, : remove_red_block\n",
            ": 16/20, : 6.3s, : remove_red_block\n",
            ": 16/20, : 7.8s, : remove_red_block\n",
            ": 16/20, : 9.3s, : remove_red_block\n",
            ": 16/20, : 10.8s, : remove_red_block\n",
            ": 16/20, : 12.4s, : remove_red_block\n",
            "\n",
            "!\n",
            " 16 : 13.4\n",
            " 17 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 17/20, : 1.7s, : remove_red_block\n",
            ": 17/20, : 3.2s, : remove_red_block\n",
            ": 17/20, : 4.8s, : remove_red_block\n",
            ": 17/20, : 6.3s, : remove_red_block\n",
            ": 17/20, : 7.9s, : remove_red_block\n",
            ": 17/20, : 9.4s, : remove_red_block\n",
            ": 17/20, : 11.0s, : remove_red_block\n",
            ": 17/20, : 12.6s, : remove_red_block\n",
            "\n",
            "!\n",
            " 17 : 13.7\n",
            " 18 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 18/20, : 1.7s, : remove_red_block\n",
            ": 18/20, : 3.2s, : remove_red_block\n",
            ": 18/20, : 4.7s, : remove_red_block\n",
            ": 18/20, : 6.3s, : remove_red_block\n",
            ": 18/20, : 7.8s, : remove_red_block\n",
            ": 18/20, : 9.3s, : remove_red_block\n",
            ": 18/20, : 10.8s, : remove_red_block\n",
            ": 18/20, : 12.3s, : remove_red_block\n",
            ": 18/20, : 13.9s, : remove_red_block\n",
            "\n",
            "!\n",
            " 18 : 14.9\n",
            " 19 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 19/20, : 1.7s, : remove_red_block\n",
            ": 19/20, : 3.2s, : remove_red_block\n",
            ": 19/20, : 4.7s, : remove_red_block\n",
            ": 19/20, : 6.2s, : remove_red_block\n",
            ": 19/20, : 7.7s, : remove_red_block\n",
            ": 19/20, : 9.3s, : remove_red_block\n",
            ": 19/20, : 10.8s, : remove_red_block\n",
            ": 19/20, : 12.3s, : remove_red_block\n",
            ": 19/20, : 13.8s, : remove_red_block\n",
            ": 19/20, : 15.4s, : remove_red_block\n",
            "\n",
            "!\n",
            " 19 : 16.0\n",
            " 20 ...\n",
            "ik_err:[0.0163] is higher than ik_err_th:[0.0100].\n",
            "You may want to increase max_ik_tick:[1000]\n",
            "DONE INITIALIZATION\n",
            ": 20/20, : 1.6s, : remove_red_block\n",
            ": 20/20, : 3.1s, : remove_red_block\n",
            ": 20/20, : 4.7s, : remove_red_block\n",
            ": 20/20, : 6.2s, : remove_red_block\n",
            ": 20/20, : 7.7s, : remove_red_block\n",
            ": 20/20, : 9.2s, : remove_red_block\n",
            ": 20/20, : 10.7s, : remove_red_block\n",
            ": 20/20, : 12.3s, : remove_red_block\n",
            "\n",
            "!\n",
            " 20 : 12.7\n",
            "\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            ": 20\n",
            ": 20\n",
            ": 0\n",
            ": 0\n",
            ": 100.00%\n",
            "\n",
            ":\n",
            "  : 16.9\n",
            "  : 12.7\n",
            "  : 68.0\n",
            "  : ['14.8s', '16.1s', '13.5s', '13.6s', '13.6s', '13.0s', '13.4s', '13.3s', '14.1s', '13.3s', '15.3s', '15.2s', '14.9s', '14.3s', '68.0s', '13.4s', '13.7s', '14.9s', '16.0s', '12.7s']\n",
            "\n",
            " (20):\n",
            "  X: [0.320, 0.320]\n",
            "  Y: [-0.200, -0.200]\n",
            "  : [0.320, -0.200, 0.850]\n",
            "\n",
            " (20):\n",
            "  : [0.320, -0.200, 0.850]\n",
            "==================================================\n",
            "MuJoCo\n",
            "\n",
            "\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            ": 20\n",
            ": 20\n",
            ": 0\n",
            ": 0\n",
            ": 100.00%\n",
            "\n",
            ":\n",
            "  : 16.9\n",
            "  : 12.7\n",
            "  : 68.0\n",
            "  : ['14.8s', '16.1s', '13.5s', '13.6s', '13.6s', '13.0s', '13.4s', '13.3s', '14.1s', '13.3s', '15.3s', '15.2s', '14.9s', '14.3s', '68.0s', '13.4s', '13.7s', '14.9s', '16.0s', '12.7s']\n",
            "\n",
            " (20):\n",
            "  X: [0.320, 0.320]\n",
            "  Y: [-0.200, -0.200]\n",
            "  : [0.320, -0.200, 0.850]\n",
            "\n",
            " (20):\n",
            "  : [0.320, -0.200, 0.850]\n",
            "==================================================\n",
            "\n",
            " :\n",
            " : 100.00%\n",
            " : 20\n",
            " : 20\n",
            " : 0\n",
            " : 0\n",
            " : 16.9\n",
            " : 12.7\n",
            " : 68.0\n",
            " MuJoCo\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "step = 0\n",
        "IMG_TRANSFORM = get_default_transform()\n",
        "\n",
        "# \n",
        "PnPEnv.start_testing(max_rounds=TEST_ROUNDS)\n",
        "policy.reset()\n",
        "policy.eval()\n",
        "\n",
        "print(f\" {TEST_ROUNDS} SmolVLA...\")\n",
        "\n",
        "while PnPEnv.env.is_viewer_alive() and PnPEnv.is_testing:\n",
        "    PnPEnv.step_env()\n",
        "    if PnPEnv.env.loop_every(HZ=20):\n",
        "        # \n",
        "        if PnPEnv.check_timeout():\n",
        "            print(f\" {PnPEnv.task_timeout} \")\n",
        "            all_tests_completed = PnPEnv.handle_task_completion(success=False, timeout=True)\n",
        "            if all_tests_completed:\n",
        "                break\n",
        "            policy.reset()\n",
        "            step = 0\n",
        "            continue\n",
        "        \n",
        "        # \n",
        "        success = PnPEnv.check_success()\n",
        "        if success:\n",
        "            print('!')\n",
        "            all_tests_completed = PnPEnv.handle_task_completion(success=True, timeout=False)\n",
        "            if all_tests_completed:\n",
        "                break\n",
        "            # policy\n",
        "            policy.reset()\n",
        "            step = 0\n",
        "            continue\n",
        "        \n",
        "        # \n",
        "        state = PnPEnv.get_joint_state()[:6]\n",
        "        # \n",
        "        image, wrist_image = PnPEnv.grab_image()\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((256, 256))\n",
        "        image = IMG_TRANSFORM(image)\n",
        "        wrist_image = Image.fromarray(wrist_image)\n",
        "        wrist_image = wrist_image.resize((256, 256))\n",
        "        wrist_image = IMG_TRANSFORM(wrist_image)\n",
        "        \n",
        "        data = {\n",
        "            'observation.state': torch.tensor([state]).to(device),\n",
        "            'observation.image': image.unsqueeze(0).to(device),\n",
        "            'observation.wrist_image': wrist_image.unsqueeze(0).to(device),\n",
        "            'task': [PnPEnv.instruction],\n",
        "        }\n",
        "        \n",
        "        # \n",
        "        action = policy.select_action(data)\n",
        "        action = action[0,:7].cpu().detach().numpy()\n",
        "        \n",
        "        # \n",
        "        _ = PnPEnv.step(action)\n",
        "        \n",
        "        # \n",
        "        progress = PnPEnv.get_test_progress()\n",
        "        if progress:\n",
        "            PnPEnv.render(idx=progress['current_round'])\n",
        "        else:\n",
        "            PnPEnv.render()\n",
        "        \n",
        "        step += 1\n",
        "        \n",
        "        #  - \n",
        "        if step % 20 == 0 and progress:  # 20\n",
        "            print(f\": {progress['current_round']}/{progress['total_rounds']}, \"\n",
        "                  f\": {progress['elapsed_time']:.1f}s, \"\n",
        "                  f\": {progress['current_task']}\")\n",
        "\n",
        "print(\"\")\n",
        "# \n",
        "if hasattr(PnPEnv, 'test_stats') and PnPEnv.test_stats['total_tests'] > 0:\n",
        "    final_results = PnPEnv.print_test_results()\n",
        "    print(\"\\n :\")\n",
        "    print(f\" : {final_results['success_rate']:.2f}%\")\n",
        "    print(f\" : {final_results['total_tests']}\")\n",
        "    print(f\" : {final_results['successful_tests']}\")\n",
        "    print(f\" : {final_results['failed_tests']}\")\n",
        "    print(f\" : {final_results['timeout_tests']}\")\n",
        "    \n",
        "    # \n",
        "    if 'success_times' in final_results and final_results['success_times']:\n",
        "        success_times = final_results['success_times']\n",
        "        avg_time = sum(success_times) / len(success_times)\n",
        "        print(f\" : {avg_time:.1f}\")\n",
        "        print(f\" : {min(success_times):.1f}\")\n",
        "        print(f\" : {max(success_times):.1f}\")\n",
        "    \n",
        "    print(\" MuJoCo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cd9ef023",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "SmolVLA  - \n",
            "============================================================\n",
            " :\n",
            "   : 20\n",
            "   : 20 \n",
            "   : 0 \n",
            "   : 0 \n",
            "\n",
            " : 100.00%\n",
            "\n",
            " :\n",
            "   : 16.9\n",
            "   : 12.7\n",
            "   : 68.0\n",
            "   : ['14.8s', '16.1s', '13.5s', '13.6s', '13.6s', '13.0s', '13.4s', '13.3s', '14.1s', '13.3s', '15.3s', '15.2s', '14.9s', '14.3s', '68.0s', '13.4s', '13.7s', '14.9s', '16.0s', '12.7s']\n",
            "    : \n",
            "\n",
            " :\n",
            "     - \n",
            "\n",
            " :\n",
            "============================================================\n",
            " MuJoCo\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "if hasattr(PnPEnv, 'test_stats') and PnPEnv.test_stats['total_tests'] > 0:\n",
        "    results = PnPEnv.test_stats\n",
        "    total = results['total_tests']\n",
        "    success = results['successful_tests']\n",
        "    failed = results['failed_tests']\n",
        "    timeout = results['timeout_tests']\n",
        "    success_times = results.get('success_times', [])\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SmolVLA  - \")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # \n",
        "    print(f\" :\")\n",
        "    print(f\"   : {total}\")\n",
        "    print(f\"   : {success} \")\n",
        "    print(f\"   : {failed} \")\n",
        "    print(f\"   : {timeout} \")\n",
        "    \n",
        "    # \n",
        "    success_rate = (success / total * 100) if total > 0 else 0\n",
        "    print(f\"\\n : {success_rate:.2f}%\")\n",
        "    \n",
        "    # \n",
        "    if success_times:\n",
        "        avg_time = sum(success_times) / len(success_times)\n",
        "        min_time = min(success_times)\n",
        "        max_time = max(success_times)\n",
        "        print(f\"\\n :\")\n",
        "        print(f\"   : {avg_time:.1f}\")\n",
        "        print(f\"   : {min_time:.1f}\")\n",
        "        print(f\"   : {max_time:.1f}\")\n",
        "        print(f\"   : {[f'{t:.1f}s' for t in success_times]}\")\n",
        "        \n",
        "        # \n",
        "        if avg_time <= 30:\n",
        "            print(f\"    : \")\n",
        "        elif avg_time <= 60:\n",
        "            print(f\"    : \")\n",
        "        elif avg_time <= 90:\n",
        "            print(f\"    : \")\n",
        "        else:\n",
        "            print(f\"    : \")\n",
        "    \n",
        "    # \n",
        "    if failed > 0:\n",
        "        timeout_rate = (timeout / failed * 100) if failed > 0 else 0\n",
        "        print(f\"\\n :\")\n",
        "        print(f\"   : {(failed / total * 100):.2f}%\")\n",
        "        print(f\"   : {timeout}  ({timeout_rate:.1f}% of failures)\")\n",
        "        print(f\"   : {failed - timeout} \")\n",
        "    \n",
        "    # \n",
        "    print(f\"\\n :\")\n",
        "    if success_rate >= 80:\n",
        "        print(\"     - \")\n",
        "    elif success_rate >= 60:\n",
        "        print(\"     - \")\n",
        "    elif success_rate >= 40:\n",
        "        print(\"     - \")\n",
        "    else:\n",
        "        print(\"     - \")\n",
        "    \n",
        "    # \n",
        "    print(f\"\\n :\")\n",
        "    if timeout > 0:\n",
        "        print(f\"   - \")\n",
        "    if success_rate < 70:\n",
        "        print(f\"   - \")\n",
        "        print(f\"   - \")\n",
        "        print(f\"   - \")\n",
        "    if success_times and avg_time > 60:\n",
        "        print(f\"   - \")\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    print(\" MuJoCo\")\n",
        "else:\n",
        "    print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "39dbec9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# []  - \n",
        "# cell\n",
        "\n",
        "# \n",
        "\"\"\"\n",
        "print(\"...\")\n",
        "PnPEnv.reset(seed=0)\n",
        "policy.reset()\n",
        "policy.eval()\n",
        "step = 0\n",
        "IMG_TRANSFORM = get_default_transform()\n",
        "\n",
        "while PnPEnv.env.is_viewer_alive():\n",
        "    PnPEnv.step_env()\n",
        "    if PnPEnv.env.loop_every(HZ=20):\n",
        "        # \n",
        "        success = PnPEnv.check_success()\n",
        "        if success:\n",
        "            print('!')\n",
        "            break\n",
        "        \n",
        "        # \n",
        "        state = PnPEnv.get_joint_state()[:6]\n",
        "        # \n",
        "        image, wrist_image = PnPEnv.grab_image()\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((256, 256))\n",
        "        image = IMG_TRANSFORM(image)\n",
        "        wrist_image = Image.fromarray(wrist_image)\n",
        "        wrist_image = wrist_image.resize((256, 256))\n",
        "        wrist_image = IMG_TRANSFORM(wrist_image)\n",
        "        \n",
        "        data = {\n",
        "            'observation.state': torch.tensor([state]).to(device),\n",
        "            'observation.image': image.unsqueeze(0).to(device),\n",
        "            'observation.wrist_image': wrist_image.unsqueeze(0).to(device),\n",
        "            'task': [PnPEnv.instruction],\n",
        "        }\n",
        "        \n",
        "        # \n",
        "        action = policy.select_action(data)\n",
        "        action = action[0,:7].cpu().detach().numpy()\n",
        "        \n",
        "        # \n",
        "        _ = PnPEnv.step(action)\n",
        "        PnPEnv.render()\n",
        "        step += 1\n",
        "        \n",
        "        # \n",
        "        if step % 50 == 0:\n",
        "            print(f\" {step} \")\n",
        "\"\"\"\n",
        "\n",
        "print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c3bb50b9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# [] MuJoCo\n",
        "# cell\n",
        "\n",
        "# \n",
        "\"\"\"\n",
        "if hasattr(PnPEnv, 'close_viewer'):\n",
        "    PnPEnv.close_viewer()\n",
        "    print(\"MuJoCo\")\n",
        "else:\n",
        "    print(\"\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9b593df4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# policy.push_to_hub(\n",
        "#     repo_id='Jeongeun/omy_pnp_smolvla',\n",
        "#     commit_message='Add trained policy for PnP task',\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9cb9032",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mujoco_vla",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
